{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入必要的Python库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from Data import Data\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformer import Transformer\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置__可视化参数__："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (20, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化__随机种子__："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置默认__浮点数类型__："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = dict()\n",
    "# for filename in os.listdir('.'):\n",
    "#     if filename.endswith('.pickle'):\n",
    "#         with open(filename, 'rb') as f:\n",
    "#             data[filename[filename.rindex('_') + 1:filename.index('.')]] = pickle.load(f)[3000:]\n",
    "# data = pd.DataFrame(data)\n",
    "# data.head(5)\n",
    "origin_data = pd.read_csv('BusTrackerData/1.csv',names=['date', 'freq'])\n",
    "origin_data = origin_data.dropna(axis=0,how='any')\n",
    "origin_data['date'] = pd.to_datetime(origin_data['date'])\n",
    "# df.reset_index(drop=True,inplace=True)\n",
    "origin_data = origin_data.set_index('date')\n",
    "\n",
    "with open('BusTrackerData/1_fourier.pkl', 'rb') as f:\n",
    "    fourier_list = pickle.load(f)\n",
    "for i, ll in enumerate(fourier_list):\n",
    "    origin_data['fourier'+str(i)] = ll\n",
    "    \n",
    "origin_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据可视化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_data.plot(subplots=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择__预测目标__："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, column in enumerate(origin_data.columns):\n",
    "    print('{}: {}'.format(i, column))\n",
    "# target = int(input('target (0~{}):'.format(len(data.columns) - 1)))\n",
    "target = 0\n",
    "assert 0 <= target < len(origin_data.columns)\n",
    "print('Your choice:', origin_data.columns[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拆分__训练数据__和__验证数据__："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = 7000\n",
    "UNI_DATA = True\n",
    "HISTORY_SIZE, TARGET_SIZE, STEP, SINGLE_STEP = 30, 0, 1, True\n",
    "data = Data(origin_data.values, target, TRAIN_SPLIT, HISTORY_SIZE, TARGET_SIZE, UNI_DATA, STEP, SINGLE_STEP)\n",
    "# print(data.x_train[0])\n",
    "# print(data.y_train[0])\n",
    "data.y_train = tf.reshape(data.y_train, [data.y_train.shape[0], data.y_train.shape[1], -1])\n",
    "data.y_val = tf.reshape(data.y_val, [data.y_val.shape[0], data.y_val.shape[1], -1])\n",
    "print(data.x_train.shape, data.x_train_target.shape, data.y_train.shape)\n",
    "print(data.x_val.shape, data.x_val_target.shape, data.y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Model = Transformer({})\n",
    "inputs = (Input([HISTORY_SIZE,1]),Input([STEP,1]))\n",
    "outputs = Model(inputs, training=True, predict_seq_length=STEP)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs, name='Transformer')\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "def model_loss(y_pred, y):\n",
    "    return mse(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置__优化器__："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义__训练步__："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, x_target, y):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        y_pred = model([tf.cast(x, tf.float32),tf.cast(y,tf.float32)], training=True)\n",
    "\n",
    "        loss = model_loss(y_pred, y)\n",
    "\n",
    "        gradients = gen_tape.gradient(loss, model.trainable_variables)\n",
    "        model_optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义__评估函数__："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data):\n",
    "    y_true, y_pred = [], []\n",
    "    for (x, x_target, y) in data:\n",
    "        y_true.extend(y)\n",
    "        y_pred.extend(model([tf.cast(x, tf.float32),tf.cast(y,tf.float32)]))\n",
    "    return mse(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义__训练循环__："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_train, data_val, epochs, steps_per_epoch):\n",
    "    loss_history = {'train_loss': [], 'val_loss': []}\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        gen_loss, disc_loss, train_loss, val_loss = None, None, None, None\n",
    "        for step, (x, x_target, y) in enumerate(data_train.repeat()):\n",
    "            if step >= steps_per_epoch:\n",
    "                break\n",
    "            gen_loss = train_step(x, x_target, y)\n",
    "        train_loss = evaluate(model, data_train)\n",
    "        val_loss = evaluate(model, data_val)\n",
    "\n",
    "        loss_history['train_loss'].append(train_loss)\n",
    "        loss_history['val_loss'].append(val_loss)\n",
    "\n",
    "        print('Time for epoch {} is {:.3f} sec. gen_loss: {:.6f}, train_loss: {:.6f}, val_loss: {:.6f}'.format(\n",
    "            epoch + 1, time.time() - start, gen_loss, train_loss, val_loss\n",
    "        ))\n",
    "\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "封装__训练数据集__和__验证数据集__："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "data_train, data_val = data.dataset(BUFFER_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型__训练__："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "STEPS_PER_EPOCH = 50\n",
    "train_history = train(data_train, data_val, EPOCHS, STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型__评估__："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_loss = evaluate(model, data_val)\n",
    "print('Evaluation MSE LOSS:', final_loss.numpy())\n",
    "# generator.save('Model/Alibaba/'+ 'LSTM-'+str(TARGET_SIZE)+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__损失函数__变化趋势："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_history(history, title):\n",
    "    train_loss = history['train_loss']\n",
    "    val_loss = history['val_loss']\n",
    "    epochs = range(len(train_loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_train_history(train_history, 'Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果展示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model(data.x_val)\n",
    "plt.plot(data.y_val, 'b-', label='actual')\n",
    "plt.plot(y_predict, 'r--', label='predict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
